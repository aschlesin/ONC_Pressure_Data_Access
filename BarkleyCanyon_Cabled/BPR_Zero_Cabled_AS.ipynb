{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to download scalar and raw data from the BPR|zero cabled at Barkley Canyon and Endeavour Main Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "\n",
    "s = requests_cache.CachedSession('requests_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceCode = 'RBRQUARTZ3BPRZERO207223'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONC_TOKEN = os.getenv('ONC_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Scalar Data using ONC Open API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_device(device_code): # date_from, date_to, sensor_category_codes,\n",
    "    url = 'https://data.oceannetworks.ca/api/scalardata'\n",
    "    params = {'method': 'getByDevice',\n",
    "                'token': os.getenv('ONC_TOKEN'),\n",
    "                'outputFormat': 'object',\n",
    "                'deviceCode': device_code,\n",
    "                'dateFrom': '2021-09-10T00:00:00.000Z',\n",
    "                'sensorCategoryCodes': 'pressure1',\n",
    "                'resampleType': 'avg',\n",
    "                'resamplePeriod': 900\n",
    "                #'dateTo': '2023-11-19T00:00:00.000Z'\n",
    "                #'dateTo': '2023-09-15T00:00:00.000Z'\n",
    "                }\n",
    "\n",
    "    response = requests.get(url=url, params=params)\n",
    "    print(response)\n",
    "    df = pd.DataFrame(response.json()['sensorData'][0]['data'])\n",
    "    df.index = pd.to_datetime(df['sampleTime'])\n",
    "    df['t'] = (df.index - df.index[0]).total_seconds()\n",
    "    return df, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the BPR|Zero data downsampled to 15min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, response = get_data_from_device(deviceCode)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_infos = []\n",
    "for sensor in response.json()['sensorData']:\n",
    "    sensor_info = {k: sensor.get(k, None) for k in ('sensorCategoryCode', 'sensorCode',\n",
    "                                                    'sensorName', 'unitOfMeasure')}\n",
    "    sensor_infos.append(sensor_info)\n",
    "    \n",
    "pd.DataFrame(sensor_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['sensorData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out pressure drops due to calibration\n",
    "df.loc[df['value']< 410.0,'value'] = float('nan')\n",
    "df.loc[df['value']> 412.0,'value'] = float('nan')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "#from scipy.stats import linregress\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exponential decay function with a constant bias\n",
    "def exponential_func_with_bias(t, A, k, b, C):\n",
    "    return A * np.exp(k * t) + b*t + C\n",
    "\n",
    "def exponential_decay_fit(df, p0=None):\n",
    "    \"\"\"\n",
    "    Fit an exponential decay curve with a constant bias to a Pandas DataFrame with 'value' and 't' columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'value' and 't' columns.\n",
    "        p0 (tuple, optional): Initial guess for parameters (A, k, C). If not provided, initial guesses will be determined automatically.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing three elements:\n",
    "            1. A numpy array representing the fitted exponential decay values.\n",
    "            2. A tuple of optimized parameters (A, k, C) where:\n",
    "                - A: Amplitude of the decay.\n",
    "                - k: Decay rate (negative).\n",
    "                - C: Constant bias term.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the DataFrame does not contain 'value' and 't' columns.\n",
    "\n",
    "    Example:\n",
    "        df = pd.DataFrame({'t': [0, 1, 2, 3, 4, 5],\n",
    "                           'value': [100, 73, 54, 40, 29, 21]})\n",
    "        result, params = exponential_decay_fit_with_bias_and_guess(df)\n",
    "        print(params)  # (106.30146425934762, -0.3709485189378329, 15.03453660968328)\n",
    "    \"\"\"\n",
    "    # Check if 'value' and 't' columns exist in the DataFrame\n",
    "    if 'value' not in df.columns or 't' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'value' and 't' columns.\")\n",
    "\n",
    "    # Extract the data from the DataFrame\n",
    "    t_data = df['t'].values\n",
    "    value_data = df['value'].values\n",
    "\n",
    "    # Fit the data to the exponential function with a constant bias\n",
    "    params, covariance = curve_fit(exponential_func_with_bias, t_data, value_data, p0=p0, maxfev=10000)\n",
    "\n",
    "    # Get the optimized parameters\n",
    "    A, k, b, C = params\n",
    "\n",
    "    # Generate the fitted curve\n",
    "    fitted_values = exponential_func_with_bias(t_data, A, k, b, C)\n",
    "\n",
    "    # Plot the original data and the fitted curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(t_data, value_data, label='Data', color='blue')\n",
    "    plt.plot(t_data, fitted_values, label='Fitted Curve', color='red')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.title('Exponential Decay Fit with Bias')\n",
    "    plt.show()\n",
    "\n",
    "    return fitted_values, params\n",
    "\n",
    "\n",
    "def estimate_decay_rate(df):\n",
    "    \"\"\"\n",
    "    Estimate the decay rate (k) for an exponential decay model using fitting and plot the results.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'value' and 't' columns.\n",
    "        \n",
    "    Returns:\n",
    "        float: Estimated decay rate (k).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the DataFrame does not contain 'value' and 't' columns.\n",
    "\n",
    "    Example:\n",
    "        df = pd.DataFrame({'t': [0, 1, 2, 3, 4, 5],\n",
    "                           'value': [100, 73, 54, 40, 29, 21]})\n",
    "        estimated_k = estimate_decay_rate_with_plot(df)\n",
    "        print(estimated_k)  # Approximately -0.413\n",
    "    \"\"\"\n",
    "    # Check if 'value' and 't' columns exist in the DataFrame\n",
    "    if 'value' not in df.columns or 't' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'value' and 't' columns.\")\n",
    "\n",
    "    # Extract the data from the DataFrame\n",
    "    t_data = df['t'].values\n",
    "    value_data = df['value'].values\n",
    "\n",
    "    # Take the natural logarithm of the values\n",
    "    ln_value_data = np.log(value_data)\n",
    "\n",
    "    # Fit an exponential decay model to the logarithmic data using polyfit\n",
    "    coeffs = np.polyfit(t_data, ln_value_data, 1)\n",
    "\n",
    "    # The coefficient is the decay rate (k)\n",
    "    estimated_k = coeffs[0]\n",
    "\n",
    "    # Calculate the fitted values\n",
    "    fitted_values = np.exp(coeffs[1]) * np.exp(estimated_k * t_data)\n",
    "\n",
    "    # Plot the original data and the fitted curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(t_data, value_data, label='Data', color='blue')\n",
    "    plt.plot(t_data, fitted_values, label='Fitted Curve', color='red')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.title('Exponential Decay Fit with Estimated k')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return estimated_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.oceannetworks.ca/api/scalardata'\n",
    "params = {'method': 'getByDevice',\n",
    "            'token': os.environ['ONC_TOKEN'],\n",
    "            'outputFormat': 'object',\n",
    "            'deviceCode': deviceCode,\n",
    "            #'rowLimit' : 10000,\n",
    "            'sensorCategoryCodes': 'systemstatus',\n",
    "            'dateFrom': '2021-09-09T00:09:30.504Z',\n",
    "            'fillGaps': 'false'\n",
    "            }\n",
    "\n",
    "response = s.get(url=url, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = pd.DataFrame(response.json()['sensorData'][0]['data'])\n",
    "cal.index = pd.to_datetime(cal['sampleTime'])\n",
    "cal['t'] = (cal.index - cal.index[0]).total_seconds()\n",
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration when value == -1\n",
    "cal = cal[['value','t']].diff().shift(-1)\n",
    "cal = cal.loc[cal['value'] == -1]\n",
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2onc(dt):\n",
    "    return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]+'Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cals = {}\n",
    "\n",
    "for ct in cal.index:\n",
    "    print(ct)\n",
    "    dt = pd.Timedelta('900s')\n",
    "    t_start = datetime2onc(ct)\n",
    "    t_end = datetime2onc(ct+dt)\n",
    "    \n",
    "    url = 'https://data.oceannetworks.ca/api/scalardata'\n",
    "    params = {'method': 'getByDevice',\n",
    "                'token': os.environ['ONC_TOKEN'],\n",
    "                'outputFormat': 'object',\n",
    "                'deviceCode':deviceCode ,\n",
    "                'dateFrom': t_start,\n",
    "                'dateTo': t_end,\n",
    "                #'sensorCategoryCodes': 'pressure1,pressure4',\n",
    "                #'resampleType': 'avg',\n",
    "                #'resamplePeriod': 60, #900\n",
    "                #'dateTo': '2023-09-15T00:00:00.000Z'\n",
    "                }\n",
    "    \n",
    "    response = s.get(url=url, params=params)\n",
    "    \n",
    "    cal_dat = pd.DataFrame()\n",
    "    #dfs = [pd.DataFrame(col['data']) for col in ]\n",
    "\n",
    "    for col in response.json()['sensorData']:\n",
    "        cal_dat[col['sensorName']] = pd.DataFrame(col['data'])['value']\n",
    "\n",
    "    cal_dat['sample time'] = pd.to_datetime(pd.DataFrame(col['data'])['sampleTime'])\n",
    "    cal_dat.index = (cal_dat['Instrument Clock'] - cal_dat['Instrument Clock'][0])*(24*3600) #.dt.total_seconds()\n",
    "    #cal_dat = pd.DataFrame([col['value'] for col in dfs], columns=['a','b'])\n",
    "    #cal_dat = pd.DataFrame(response.json()['sensorData'][0]['data'])\n",
    "    #cal_dat.index = pd.to_datetime(cal_dat['sampleTime'])\n",
    "    #cal_dat['t'] = (cal_dat.index - cal_dat.index[0]).total_seconds()\n",
    "    \n",
    "    # calibrated pressure timeseries\n",
    "    cals[ct] = (cal_dat['AZA Raw Pressure']-cal_dat['AZA Reference Pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame() #index=pd.Index(range(1790))\n",
    "keys = list(cals.keys())\n",
    "for key in keys:\n",
    "    #print(len(cals[key]))\n",
    "    a[key] = cals[key].iloc[0:-1].reset_index(drop=True)\n",
    "\n",
    "#a = cals[keys[0]]\n",
    "#a.reindex_like(pd.NumericIndex(np.arange(0, 600, 0.125)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take care of 8 Hz sample rate\n",
    "a.index = a.index/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.rolling(16, center=True).mean()#.iloc[800:660*8,:]\n",
    "b = b.loc[:,b.max()< 100]\n",
    "b.plot(figsize=(12,12), grid=True, legend=False,\n",
    "            xlabel='Time after start of calibration (s)',\n",
    "            ylabel='Transfer Pressure  - Reference Pressure (dbar)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get BPR data from different locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(locationCode, deviceCategoryCode, sensorCategoryCodes = 'pressure', dateFrom = '2009-08-01T00:00:00.000Z', session = None):\n",
    "\n",
    "    url = 'http://data.oceannetworks.ca/api/scalardata'\n",
    "\n",
    "    params = {\n",
    "        'method': 'getByLocation',\n",
    "        'token': os.environ['ONC_TOKEN'],\n",
    "        'deviceCategoryCode': deviceCategoryCode,\n",
    "        'locationCode': locationCode,\n",
    "        'sensorCategoryCodes': sensorCategoryCodes,\n",
    "        'resamplePeriod': 900,\n",
    "        'resampleType': 'avgMinMax',\n",
    "        'dateFrom': dateFrom,\n",
    "    }\n",
    "    \n",
    "    dfs = []\n",
    "\n",
    "    while 1:\n",
    "        print(params['dateFrom'])\n",
    "        if session:\n",
    "            r = session.get(url, params=params)\n",
    "        else:\n",
    "            r = requests.get(url, params=params)\n",
    "            \n",
    "        df = pd.DataFrame(r.json()['sensorData'][0]['data'])\n",
    "        df.index = pd.DatetimeIndex(df['sampleTimes'])\n",
    "        dfs.append(df)\n",
    "        try:\n",
    "            params['dateFrom'] = r.json()['next']['parameters']['dateFrom']\n",
    "        except TypeError:\n",
    "            break\n",
    "        \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_data_by_location(device_category_code='BPR', location_code = 'MEFS', sensor_category_codes='pressure1'): # date_from, date_to, sensor_category_codes,\n",
    "\n",
    "bpr_z = getData('NCBC.P1', 'BPR', sensorCategoryCodes='pressure1', dateFrom='2021-09-10', session=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbc = getData('NCBC', 'BPR', sensorCategoryCodes='pressure', dateFrom='2021-09-10', session=s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the calibration jumps from BPRZero ambient pressure\n",
    "bpr_z['values'][0:200].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean BPRZero pressure sensor values of calibration jumps\n",
    "\n",
    "bpr_z['cleaned'] = bpr_z['values'].copy()\n",
    "bpr_z.loc[bpr_z['cleaned']< 409,'cleaned'] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCBC comparison\n",
    "# get NCBC for BPRZero dates and subtract BPRzero pressure\n",
    "ec_diff = (ncbc['values'].reindex_like(bpr_z['cleaned'])-bpr_z['cleaned'])\n",
    "\n",
    "ec_diff = ec_diff - ec_diff.iloc[0]\n",
    "ec_diff[ec_diff > 0.2] = float('nan')\n",
    "ec_diff[ec_diff < -0.002] = float('nan')\n",
    "\n",
    "ax = ec_diff.plot(grid=True, figsize=(12,8), label='NCBC -  BPR-Z')\n",
    "ec_diff.rolling('25h', center=True).mean().plot(ax=ax,grid=True, figsize=(12,8),label='25h rolling mean')\n",
    "\n",
    "# adjust the calibrations to fit the drift curve at the beginning (exponential part)\n",
    "#(-1*(cal - cal.iloc[0]) - 0.02).plot(ax = ax, figsize=(12,8), grid=True, marker='.', label='Calibration')\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Pressure difference (dbar | m)')\n",
    "ax.legend()\n",
    "ax.set_title('NCBC vs BPR Zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCBC zoom\n",
    "# get NCBC for BPRZero dates and subtract BPRzero pressure\n",
    "ec_diff = (ncbc['values'].reindex_like(bpr_z['cleaned'])-bpr_z['cleaned'])\n",
    "\n",
    "ec_diff = ec_diff - ec_diff.iloc[0]\n",
    "ec_diff[ec_diff > 0.2] = float('nan')\n",
    "ec_diff[ec_diff < -0.002] = float('nan')\n",
    "ax = ec_diff.plot(grid=True, figsize=(12,8), label='NCBC vs BPR-Z')\n",
    "ec_diff.rolling('25h', center=True).mean().plot(ax=ax,grid=True, figsize=(12,8),label='25h rolling mean')\n",
    "\n",
    "#(-1*(cal - cal.iloc[0]) - 0.02).plot(ax = ax, figsize=(12,8), grid=True, marker='.',markersize=12.5, label='Calibration')\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_xlim(['2021-09-01 00:00','2022-03-01 00:00'])\n",
    "ax.set_ylabel('Pressure difference (dbar | m)')\n",
    "ax.legend()\n",
    "ax.set_title('NCBC vs BPR Zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get archived raw data via ONC Open API client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from onc import ONC\n",
    "onc = ONC(token=os.getenv('ONC_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "                'deviceCode': deviceCode,\n",
    "                'dateFrom': '2022-04-05T00:00:00.000Z',\n",
    "                'dateTo': '2022-04-06T00:00:00.000Z'\n",
    "                #'dateTo': '2023-09-15T00:00:00.000Z'\n",
    "                }\n",
    "                \n",
    "data = onc.getDirectRawByDevice(params, allPages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data']['lineTypes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(pd.to_datetime(df['times']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['readings'].str.contains('deployment status', na=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 1. Find the physical integer positions of all rows containing 'Driver'\n",
    "match_positions = np.where(df['readings'].str.contains('deployment status', na=False))[0]\n",
    "\n",
    "# 2. Check to make sure we actually found a match\n",
    "if len(match_positions) > 0:\n",
    "    # Get the position of the FIRST time 'Driver' appears\n",
    "    first_match_pos = match_positions[0]\n",
    "    \n",
    "    # 3. Use .iloc to grab the next 10 rows (from position + 1, to position + 11)\n",
    "    next_100_rows = df.iloc[first_match_pos + 1 : first_match_pos + 100]['readings']\n",
    "    \n",
    "    print(next_100_rows)\n",
    "else:\n",
    "    print(\"The word 'Driver' was not found in the DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obspy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
